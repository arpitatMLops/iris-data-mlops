name: CI/CD â€” build image, upload templates, deploy via Lambda

on:
  push:
    branches: [ main ]

permissions:
  contents: read
  id-token: write

env:
  AWS_REGION: eu-north-1
  ECR_REPOSITORY: iris-mlops-prototype
  ECR_IMAGE_TAG: latest
  S3_BUCKET: iris-mlops-bucket-182406535835
  LAMBDA_S3_KEY: lambda_deploy/lambda.zip
  PIPELINE_TEMPLATE_KEY: iris-mlops-pipeline.yaml
  INFRA_TEMPLATE_KEY: infra.yaml
  LAMBDA_LOCAL_ZIP: lambda.zip
  LAMBDA_HANDLER_FILE: lambda_trigger.py
  INFRA_STACK_NAME: iris-mlops-infra
  PIPELINE_STACK_NAME: iris-mlops-pipeline

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Install OS deps (zip, jq)
        run: |
          sudo apt-get install -y zip jq || true


      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Set account id
        id: acct
        run: |
          echo "AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)" >> $GITHUB_OUTPUT

      - name: Create ECR repo if missing and login
        run: |
          ECR_REGISTRY="${{ steps.acct.outputs.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com"
          echo "ECR_REGISTRY=$ECR_REGISTRY" >> $GITHUB_ENV
          aws ecr describe-repositories --repository-names "${{ env.ECR_REPOSITORY }}" >/dev/null 2>&1 || \
            aws ecr create-repository --repository-name "${{ env.ECR_REPOSITORY }}" || true
          aws ecr get-login-password --region "${{ env.AWS_REGION }}" | docker login --username AWS --password-stdin "$ECR_REGISTRY"

      - name: Build and push Docker image to ECR
        run: |
          ECR_REGISTRY="${{ steps.acct.outputs.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com"
          IMAGE="${ECR_REGISTRY}/${{ env.ECR_REPOSITORY }}:${{ env.ECR_IMAGE_TAG }}"
          if [ -f Dockerfile ]; then
            docker build -t "$IMAGE" .
            docker push "$IMAGE"
            echo "IMAGE_URI=$IMAGE" >> $GITHUB_ENV
          else
            echo "No Dockerfile found, skipping Docker build/push"
          fi

      - name: Zip Lambda code
        run: |
          if [ ! -f "${{ env.LAMBDA_HANDLER_FILE }}" ]; then
            echo "ERROR: ${LAMBDA_HANDLER_FILE} not found in repo root"
            exit 1
          fi
          zip -r "${{ env.LAMBDA_LOCAL_ZIP }}" "${{ env.LAMBDA_HANDLER_FILE }}"

      - name: Upload lambda.zip to S3
        run: |
          aws s3 cp "${{ env.LAMBDA_LOCAL_ZIP }}" "s3://${{ env.S3_BUCKET }}/${{ env.LAMBDA_S3_KEY }}"

      - name: Upload CloudFormation templates to S3
        run: |
          if [ ! -f infra.yaml ]; then
            echo "ERROR: infra.yaml missing"
            exit 1
          fi
          if [ ! -f iris-mlops-pipeline.yaml ]; then
            echo "ERROR: iris-mlops-pipeline.yaml missing"
            exit 1
          fi
          aws s3 cp infra.yaml "s3://${{ env.S3_BUCKET }}/${{ env.INFRA_TEMPLATE_KEY }}"
          aws s3 cp iris-mlops-pipeline.yaml "s3://${{ env.S3_BUCKET }}/${{ env.PIPELINE_TEMPLATE_KEY }}"

      - name: Build payload.json for deployer Lambda
        env:
          AWS_ACCOUNT_ID: ${{ steps.acct.outputs.AWS_ACCOUNT_ID }}
          AWS_REGION: ${{ env.AWS_REGION }}
          S3_BUCKET: ${{ env.S3_BUCKET }}
          INFRA_TEMPLATE_KEY: ${{ env.INFRA_TEMPLATE_KEY }}
          PIPELINE_TEMPLATE_KEY: ${{ env.PIPELINE_TEMPLATE_KEY }}
          ECR_REPOSITORY: ${{ env.ECR_REPOSITORY }}
          ECR_IMAGE_TAG: ${{ env.ECR_IMAGE_TAG }}
          SAGEMAKER_ROLE_ARN: ${{ secrets.SAGEMAKER_ROLE_ARN }}
        run: |
          python3 - <<'PY'
          import json, os, sys
          
          AWS_ACCOUNT_ID = os.getenv("AWS_ACCOUNT_ID","")
          AWS_REGION = os.getenv("AWS_REGION","eu-north-1")
          S3_BUCKET = os.getenv("S3_BUCKET")
          INFRA_KEY = os.getenv("INFRA_TEMPLATE_KEY")
          PIPELINE_KEY = os.getenv("PIPELINE_TEMPLATE_KEY")
          ECR_REPOSITORY = os.getenv("ECR_REPOSITORY")
          ECR_IMAGE_TAG = os.getenv("ECR_IMAGE_TAG")
          SAGEMAKER_ROLE_ARN = os.getenv("SAGEMAKER_ROLE_ARN","")
          
          if not S3_BUCKET or not INFRA_KEY or not PIPELINE_KEY:
              print("ERROR: required env vars missing (S3_BUCKET/INFRA_TEMPLATE_KEY/PIPELINE_TEMPLATE_KEY)", file=sys.stderr)
              sys.exit(2)
          
          image_uri = f"{AWS_ACCOUNT_ID}.dkr.ecr.{AWS_REGION}.amazonaws.com/{ECR_REPOSITORY}:{ECR_IMAGE_TAG}"
          
          payload = {
            "InfraTemplateS3": f"s3://{S3_BUCKET}/{INFRA_KEY}",
            "PipelineTemplateS3": f"s3://{S3_BUCKET}/{PIPELINE_KEY}",
            "InfraParameters": {
              "ProjectName": "iris-mlops",
              "SageMakerRoleArn": SAGEMAKER_ROLE_ARN
            },
            "PipelineParameters": {
              "ProjectName": "iris-mlops",
              "ECRImageURI": image_uri,
              "S3BucketName": S3_BUCKET,
              "SageMakerRoleArn": SAGEMAKER_ROLE_ARN
            },
            "Capabilities": ["CAPABILITY_NAMED_IAM"]
          }
          
          with open("payload.json","w") as f:
              json.dump(payload, f, indent=2)
          print("payload.json written:")
          with open("payload.json") as f:
              print(f.read())
          PY

      - name: Invoke deployer Lambda
        run: |
          LAMBDA_NAME="${{ secrets.LAMBDA_NAME }}"
          if [ -z "$LAMBDA_NAME" ]; then
            echo "ERROR: set secret LAMBDA_NAME to your deployer Lambda function name"
            exit 1
          fi
          echo "Invoking deployer Lambda: $LAMBDA_NAME"
          aws lambda invoke --function-name "$LAMBDA_NAME" --payload file://payload.json --cli-binary-format raw-in-base64-out response.json
          echo "Deployer response:"
          cat response.json
